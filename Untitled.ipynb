{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equadratures import polytree \n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_1(x, noise):\n",
    "    \n",
    "    if noise:\n",
    "        noise = 0.1 * st.norm.rvs(0, 1)\n",
    "    else:\n",
    "        noise = 0\n",
    "    if x < 0.5:\n",
    "        return 25*(x-0.25)**2 - 1.0625 + noise\n",
    "    elif x > 0.5:\n",
    "        return 25*(x-0.75)**2 - 1.0625 + noise\n",
    "    \n",
    "def sample_1():\n",
    "    X, y = [], []\n",
    "    for i in range(100):\n",
    "        x = random.random()    \n",
    "        X.append(np.array([x]))\n",
    "        y.append(np.array([f_1(x, False)]))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.asarray([[0.53669716],[0.9418995],[0.10015618],[0.54943849],[0.92377753],[0.53039907],[0.056789],[0.91385676],[0.04362725],[0.55554194],[0.8058076],[0.31561277],[0.46891515],[0.93001163],[0.99958221],[0.36501935],[0.57390696],[0.83657814],[0.99351013],[0.93007124],[0.47721519],[0.77966253],[0.48478384],[0.18098933],[0.17659877],[0.26844927],[0.78430287],[0.2987737],[0.58719587],[0.76437959],[0.4224177],[0.486552],[0.3386876],[0.74107937],[0.34056682],[0.09831047],[0.62991656],[0.01340558],[0.83284695],[0.56046375],[0.76037261],[0.17244924],[0.991193],[0.15664048],[0.8467371],[0.69392759],[0.76512442],[0.29214428],[0.67558101],[0.50121273],[0.46629595],[0.98380071],[0.9840702],[0.53743918],[0.42861985],[0.59796375],[0.31601077],[0.56847489],[0.91679277],[0.36065183],[0.38922106],[0.47319992],[0.18896924],[0.99164541],[0.46904421],[0.56468748],[0.39920275],[0.39339238],[0.01272458],[0.81304688],[0.04680516],[0.2743472],[0.18162223],[0.93079232],[0.98649198],[0.78216601],[0.12267744],[0.79789631],[0.28880751],[0.09549659],[0.43465827],[0.73619068],[0.12667353],[0.70486126],[0.63840303],[0.94418287],[0.59370177],[0.71322119],[0.8090448],[0.32912165],[0.24397756],[0.80316342],[0.06554426],[0.28455772],[0.58468597],[0.39562895],[0.49259921],[0.38923876],[0.34158604],[0.13276555]])\n",
    "#y_train = np.asarray([[0.07495255],[-0.14186451],[-0.5011707],[-0.05687701],[-0.30753425],[0.14311424],[-0.1292377],[-0.39127408],[0.00224281],[-0.11715155],[-0.9846378],[-0.95487409],[0.13559611],[-0.25239534],[0.49478202],[-0.73176374],[-0.28728102],[-0.87510564],[0.41992954],[-0.25185868],[0.22816862],[-1.04050336],[0.31558625],[-0.94343817],[-0.92780649],[-1.05399061],[-1.03308283],[-1.00302814],[-0.39987035],[-1.05733068],[-0.31930343],[0.33642123],[-0.86586274],[-1.06051056],[-0.85744128],[-0.48725714],[-0.70199921],[0.33692298],[-0.89090956],[-0.16440029],[-1.05981023],[-0.912147],[0.39185157],[-0.84460001],[-0.82854836],[-0.98389713],[-1.0567813],[-1.0180965],[-0.92404536],[0.48487768],[0.10709842],[0.30406931],[0.30722146],[0.06705255],[-0.26487369],[-0.48462448],[-0.95356446],[-0.23871589],[-0.36700432],[-0.75640432],[-0.57793743],[0.18295508],[-0.96938117],[0.39731257],[0.1370091],[-0.20398175],[-0.50596345],[-0.5484656],[0.34499062],[-0.96312728],[-0.03029643],[-1.04768035],[-0.94561201],[-0.24535341],[0.3357114],[-1.0366337],[-0.65722415],[-1.00514858],[-1.02484942],[-0.46571741],[-0.21003313],[-1.05773257],[-0.68226455],[-1.01156236],[-0.75115288],[-0.11982531],[-0.45177157],[-1.02868297],[-0.97534279],[-0.90599413],[-1.06159326],[-0.99184127],[-0.21190204],[-1.03264411],[-0.37928179],[-0.53230523],[0.40885942],[-0.57781419],[-0.85279994],[-0.7189021]])\n",
    "\n",
    "#x_test = np.asarray([[0.67005087],[0.20878885],[0.84729824],[0.08890635],[0.10506394],[0.77753457],[0.9029504 ],[0.01981286],[0.57339535],[0.32254891],[0.9526776 ],[0.97165053],[0.88101978],[0.23046062],[0.94885323],[0.53430128],[0.42882352],[0.05385337],[0.68920086],[0.82169622]])\n",
    "#y_test = np.asarray([[-0.90270341],[-1.02004102],[-0.8258263 ],[-0.41372088],[-0.53733846],[-1.04354619],[-0.47765441],[ 0.26215302],[-0.28276993],[-0.93091639],[-0.03554479],[ 0.16572399],[-0.63334544],[-1.05295532],[-0.07393487],[ 0.10064844],[-0.26305373],[-0.10066247],[-0.97008661],[-0.9339913 ]])\n",
    "\n",
    "#y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "#y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "losses = []\n",
    "for i in range(200):\n",
    "    X, y = sample_1()\n",
    "    X_train, X_test = X[:80], X[-20:]\n",
    "    y_train, y_test = y[:80], y[-20:]\n",
    "    tree = polytree.PolyTree(search='exhaustive')\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    loss = np.linalg.norm(y_test - tree.predict(X_test).reshape(-1)) / y_test.shape[0]\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3872075676526388,\n",
       " 0.4436036820386657,\n",
       " 0.3837162446396777,\n",
       " 0.5089404756419318,\n",
       " 0.4900580743587035,\n",
       " 0.48390858216934085,\n",
       " 0.5549787140222869,\n",
       " 0.5065253525440356,\n",
       " 0.5246311692973741,\n",
       " 0.45860175316526763,\n",
       " 0.4703895899055448,\n",
       " 0.5825846572156397,\n",
       " 0.43087970912996526,\n",
       " 0.5031877616321206,\n",
       " 0.41857876612421396,\n",
       " 0.5070354326191093,\n",
       " 0.5245272383521375,\n",
       " 0.5423254561262212,\n",
       " 0.38047158321065044,\n",
       " 0.5385723883604612,\n",
       " 0.3925898751068594,\n",
       " 0.4698027220535536,\n",
       " 0.43728051137727403,\n",
       " 0.43658698917241734,\n",
       " 0.4247934879130694,\n",
       " 0.3727917482292059,\n",
       " 0.5693856376446637,\n",
       " 0.3971086503574523,\n",
       " 0.4982185028535781,\n",
       " 0.5284751048407711,\n",
       " 0.4244394296730129,\n",
       " 0.6172168487226213,\n",
       " 0.5271293210520851,\n",
       " 0.6100901105543064,\n",
       " 0.5654399049351257,\n",
       " 0.47934537138893435,\n",
       " 0.8030366565906359,\n",
       " 0.287187348336059,\n",
       " 0.6321818169951794,\n",
       " 0.6419812081899031,\n",
       " 0.42001734672540547,\n",
       " 0.4163790782088044,\n",
       " 0.5159399292525618,\n",
       " 0.45542184189300217,\n",
       " 0.39873090239792475,\n",
       " 0.6280155712267317,\n",
       " 0.4851110265081817,\n",
       " 0.5923886972770148,\n",
       " 0.5180768551095378,\n",
       " 0.658419116132474,\n",
       " 0.5831862195283742,\n",
       " 0.5285212951359235,\n",
       " 0.699673083090724,\n",
       " 0.5727147872299009,\n",
       " 0.558500999141095,\n",
       " 0.5111958806396633,\n",
       " 0.4288716855839053,\n",
       " 0.5091916085048293,\n",
       " 0.4426403052766039,\n",
       " 0.4275148747224282,\n",
       " 0.49114361129245987,\n",
       " 0.48013836496474155,\n",
       " 0.49813625702163267,\n",
       " 0.5131397366711694,\n",
       " 0.4761157462658067,\n",
       " 0.4205659482750357,\n",
       " 0.49006476750494965,\n",
       " 0.372823731270614,\n",
       " 0.48392621382687173,\n",
       " 0.6149747654008209,\n",
       " 0.4096147914510208,\n",
       " 0.49745131749621097,\n",
       " 0.43709383617233294,\n",
       " 0.39130510806003593,\n",
       " 0.5103220003315808,\n",
       " 0.53480208992896,\n",
       " 0.4856395720706053,\n",
       " 0.5398732027711681,\n",
       " 0.5028221519261632,\n",
       " 0.6650387351752489,\n",
       " 0.4997980681972254,\n",
       " 0.48965029609493593,\n",
       " 0.4445990630686965,\n",
       " 0.5220642085680002,\n",
       " 0.48479338138362166,\n",
       " 0.5910603330149664,\n",
       " 0.5223899985729094,\n",
       " 0.4790063888993685,\n",
       " 0.6369584005854059,\n",
       " 0.527867689130668,\n",
       " 0.43822763054907216,\n",
       " 0.5177174594153499,\n",
       " 0.4634516895953166,\n",
       " 0.5531504600166057,\n",
       " 0.35903184288462364,\n",
       " 0.5662142217305735,\n",
       " 0.38714200585221176,\n",
       " 0.4730874710693568,\n",
       " 0.43628472460274975,\n",
       " 0.5356806731346209,\n",
       " 0.4877411048189445,\n",
       " 0.4889437009038497,\n",
       " 0.5380453303285027,\n",
       " 0.5141232444341032,\n",
       " 0.5883412436756812,\n",
       " 0.48150989880794615,\n",
       " 0.4122580692157703,\n",
       " 0.5642168503512858,\n",
       " 0.5687269371309422,\n",
       " 0.45922244249791405,\n",
       " 0.4613628775847528,\n",
       " 0.43916979017876584,\n",
       " 0.5176156859416037,\n",
       " 0.5870137393138838,\n",
       " 0.3946882955789034,\n",
       " 0.7601630973913215,\n",
       " 0.3183025658065518,\n",
       " 0.4866083952706406,\n",
       " 0.48342386432293283,\n",
       " 0.49258860354067735,\n",
       " 0.4075409134476685,\n",
       " 0.441719816962378,\n",
       " 0.48666255048506607,\n",
       " 0.3984394026821446,\n",
       " 0.38140696308416133,\n",
       " 0.4916190213239302,\n",
       " 0.6368984125150031,\n",
       " 0.5254292124167634,\n",
       " 0.5015761278223867,\n",
       " 0.5923975654989687,\n",
       " 0.43856215167663803,\n",
       " 0.5437440047871341,\n",
       " 0.5433591699915061,\n",
       " 0.5510079488535018,\n",
       " 0.671736928169836,\n",
       " 0.4687395472234915,\n",
       " 0.6152819330377303,\n",
       " 0.553873299746907,\n",
       " 0.6892595351239609,\n",
       " 0.6974667029681162,\n",
       " 0.48411643527536424,\n",
       " 0.6124141062424833,\n",
       " 0.5551991548945016,\n",
       " 0.5521389252872713,\n",
       " 0.5280457098647224,\n",
       " 0.47799396674223094,\n",
       " 0.606456879350598,\n",
       " 0.530186686568735,\n",
       " 0.5164570809629436,\n",
       " 0.5504564088958426,\n",
       " 0.4721430015351177,\n",
       " 0.6302435140098525,\n",
       " 0.5374467349860232,\n",
       " 0.44695302250048785,\n",
       " 0.4673348239319064,\n",
       " 0.48425072602238284,\n",
       " 0.4983895483804391,\n",
       " 0.5015373164025788,\n",
       " 0.5949985383696297,\n",
       " 0.6440500506385926,\n",
       " 0.49801486620342705,\n",
       " 0.5183265322873881,\n",
       " 0.5744826332410197,\n",
       " 0.5560963479147623,\n",
       " 0.7101569278588555,\n",
       " 0.6858409116722771,\n",
       " 0.4604488012510658,\n",
       " 0.5319972503062098,\n",
       " 0.5348532385958509,\n",
       " 0.5052849140975898,\n",
       " 0.4720572549220587,\n",
       " 0.5614890127708743,\n",
       " 0.5327298876454193,\n",
       " 0.49068387874920083,\n",
       " 0.41468530674850107,\n",
       " 0.7117132084843428,\n",
       " 0.43272579283873747,\n",
       " 0.5327325356809964,\n",
       " 0.6248895975906861,\n",
       " 0.4544129940093299,\n",
       " 0.5585528656155533,\n",
       " 0.4942825049985446,\n",
       " 0.49367660074529374,\n",
       " 0.38443310777000633,\n",
       " 0.3866776808717394,\n",
       " 0.442012635364322,\n",
       " 0.5244646946876719,\n",
       " 0.5322490504773055,\n",
       " 0.5326844831577437,\n",
       " 0.47777248225896196,\n",
       " 0.5060819844917989,\n",
       " 0.4934002055118465,\n",
       " 0.4482800321145001,\n",
       " 0.6253382979975247,\n",
       " 0.4654317986315634,\n",
       " 0.4802816654769231,\n",
       " 0.7059867355084982,\n",
       " 0.3943952061118511,\n",
       " 0.5180389896320465,\n",
       " 0.48898686550024706]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08265130047959919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = stats.norm.fit(losses)\n",
    "mean\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7802276710276717"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm.ppf(0.999, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dreampuf.github.io/GraphvizOnline/#digraph%20g%20%7B%0A%09node%20%5Bheight%3D.1%20shape%3Drecord%5D%0A%09node%20%5Blabel%3D%22%20n_samples%20%3D%2080%5Cn%20loss%20%3D%200.420934%22%20shape%3Drectangle%5D%0A%09node1%20%5Bcolor%3Dblack%20fillcolor%3Dwhite%20fontcolor%3Dblack%20style%3Dfilled%5D%0A%7D\n"
     ]
    }
   ],
   "source": [
    "tree.get_graphviz(['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "X2 = np.linspace(0, 1, num=10)\n",
    "X = np.meshgrid(X1, X2)\n",
    "y = [np.exp(-(x[0]**2 + x[1]**2)) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False,  True, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False,  True, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False,  True, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False, False,  True, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False, False, False,  True, False, False,\n",
       "        False],\n",
       "       [False, False, False, False, False, False, False,  True, False,\n",
       "        False],\n",
       "       [False, False, False, False, False, False, False, False,  True,\n",
       "        False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "         True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] == X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
